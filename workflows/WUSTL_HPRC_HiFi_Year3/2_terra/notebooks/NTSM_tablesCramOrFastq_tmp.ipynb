{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Data Tables For HiFi Data QC<a class=\"tocSkip\">\n",
    "\n",
    "**This notebook automatically reads in data stored in the AnVIL_HPRC workspace's bucket and generates data table so the data can be run through QC (NTSM and ReadStat's WDLs)**\n",
    "\n",
    "**Jeltje changed this in Feb 2023 to output per-file tables instead of per-sample**\n",
    "\n",
    "**Below are the steps taken in this notebook:**\n",
    "1. Import Statements & Global Variable Definitions\n",
    "2. Define Functions\n",
    "3. Read In Sample Names\n",
    "4. Create Dataframe Of Files\n",
    "5. Write data frame to data tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Statements & Global Variable Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install gcsfs\n",
    "## capture CANNOT have comments above it\n",
    "## For reading CSVs stored in Google Cloud (without downloading them first)\n",
    "## May need to restart kernel after install "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install --upgrade --no-cache-dir --force-reinstall terra-pandas\n",
    "%pip install --upgrade --no-cache-dir  --force-reinstall git+https://github.com/DataBiosphere/terra-notebook-utils\n",
    "## For reading/writing data tables into pandas data frames\n",
    "## May need to restart kernel after install "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from firecloud import fiss\n",
    "import pandas as pd         \n",
    "import os                 \n",
    "import subprocess       \n",
    "import re                 \n",
    "import io\n",
    "import gcsfs\n",
    "\n",
    "from typing import Any, Callable, List, Optional\n",
    "from terra_notebook_utils import table, WORKSPACE_NAME, WORKSPACE_GOOGLE_PROJECT\n",
    "from terra_pandas import dataframe_to_table, table_to_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Variable Declarations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Billing project: human-pangenome-ucsc\n",
      "Workspace: HPRC_WRANGLING_WUSTL_HPRC_HiFi_Year3\n",
      "Workspace storage bucket: gs://fc-a7e6ae6b-860b-4519-80a5-277aeb967124/\n"
     ]
    }
   ],
   "source": [
    "# AnVIL_HPRC WorkspaceBucket\n",
    "anvil_hprc_bucket       = \"gs://fc-4310e737-a388-4a10-8c9e-babe06aaf0cf/\"\n",
    "\n",
    "# Get the Google billing project name and workspace name for current workspace\n",
    "PROJECT = os.environ['WORKSPACE_NAMESPACE']\n",
    "WORKSPACE =os.path.basename(os.path.dirname(os.getcwd()))\n",
    "bucket = os.environ['WORKSPACE_BUCKET'] + \"/\"\n",
    "\n",
    "\n",
    "# Verify that we've captured the environment variables\n",
    "print(\"Billing project: \" + PROJECT)\n",
    "print(\"Workspace: \" + WORKSPACE)\n",
    "print(\"Workspace storage bucket: \" + bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def rtn_datatype_ls_for_subm(bucket_url, submission_key, data_type_subdir, file_type_ls):\n",
    "    '''Takes in:\n",
    "            * bucket_url (string): url of bucket to search (should be the AnVIL_HPRC bucket)\n",
    "                ex: \"gs://fc-4310e737-a388-4a10-8c9e-babe06aaf0cf/\"\n",
    "            * submission_key (string): the UUID plus the submission name to search\n",
    "                ex: \"5c68b972-8534-402f-9861-11c93558765f--UW_HPRC_HiFi_Y3\"\n",
    "            * data_type_subdir (string): name of the subfolder to search \n",
    "              (used when a submission has more than one data type.)\n",
    "                ex: \"PacBio_HiFi\" if the data is not in subfolders, pass \".\"\n",
    "            * file_type_ls (list of strings): file extensions to search for. Often a submission will \n",
    "              have more than one type of file that represents the same dataset. Be careful to not \n",
    "              include replicate data, however.\n",
    "                ex: \".hifi_reads.bam\"\n",
    "     then performs a list of the bucket, then returns a filtered list files.'''\n",
    "    \n",
    "    rtn_file_ls = []\n",
    "    \n",
    "    submission_path = str(bucket_url + \"submissions/\" + submission_key)\n",
    "    file_list_byt   = subprocess.run(['gsutil', '-u', 'human-pangenome-ucsc', 'ls', '-r', submission_path], \n",
    "                                     stdout=subprocess.PIPE)\n",
    "\n",
    "    file_list_str   = file_list_byt.stdout.decode('utf-8')\n",
    "    file_list       = file_list_str.split('\\n')  ## Pull out \"\\n\"\n",
    "   \n",
    "    ## filter out empty strings\n",
    "    file_list = [ elem for elem in file_list if elem != '']\n",
    "    \n",
    "    ## Pull from subdir type we are targeting\n",
    "    file_list = list(filter(lambda x:re.search(rf\"{data_type_subdir}\", x), file_list))\n",
    "    \n",
    "    for file_type in file_type_ls:\n",
    "    \n",
    "        ## Pull files of correct type (ex: ccs.bam)\n",
    "        file_list_by_type = list(filter(lambda x:re.search(rf\"{file_type}$\", x), file_list))\n",
    "\n",
    "        ## Add to list of files to return\n",
    "        rtn_file_ls += file_list_by_type\n",
    "\n",
    "    return rtn_file_ls    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read In Sample Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This file (a list of sample IDs) should be stored in the Terra workspace (in the bucket) that is being used for \n",
    "## the submission you  are wrangling...\n",
    "sample_info_fp = \"gs://fc-a7e6ae6b-860b-4519-80a5-277aeb967124/WUSTL_HPRC_HiFi_Year3.csv\"\n",
    "\n",
    "sample_df = pd.read_csv(sample_info_fp, header=None)\n",
    "\n",
    "sample_df.rename(columns = {0:'sample_id'}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Dataframe Of Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "subm_key         = \"c0de0f97-f422-4057-90bd-12b40869d30a--WUSTL_HPRC_HiFi_Year3\"\n",
    "data_type_subdir = \".\"\n",
    "file_type_ls     = [\".hifi_reads.bam\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get a list of the files in submission (subm_key) that match the \n",
    "## data_type_subdir and file_type_ls\n",
    "## NOTE: if this gets a service account warning, wait 24 hours (?) for the workspace to get added\n",
    "file_ls  = rtn_datatype_ls_for_subm(anvil_hprc_bucket, subm_key, \n",
    "                                      data_type_subdir, file_type_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Check that the number of files matches what we expect\n",
    "len(file_ls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Sample Data To File Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79\n"
     ]
    }
   ],
   "source": [
    "filedict = dict()\n",
    "\n",
    "for f in file_ls:\n",
    "    for s in sample_df.sample_id:\n",
    "        if re.search(s,f):\n",
    "            filedict[f] = s\n",
    "            break            \n",
    "print(len(filedict))\n",
    "file_df = pd.DataFrame.from_dict(filedict.items())\n",
    "file_df.columns = ['hifi', 'sample']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add 1000G data (for NTSM run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read in 1000G data from another workspace\n",
    "## We will be using this to compare against out submission to make sure that\n",
    "## the data comes from the same samples\n",
    "thousand_genomes_df = table_to_dataframe(\"sample\", \n",
    "                                        workspace=\"1000G-high-coverage-2019\", \n",
    "                                        workspace_namespace=\"anvil-datastorage\")\n",
    "## Use the 1kg library name (i.e. HG00621) as the index (that matches our sample name)\n",
    "thousand_genomes_df.set_index('library_name', inplace=True)\n",
    "\n",
    "## We only need the cram file (represents 30X Ilmn dataset)\n",
    "thousand_genomes_df = thousand_genomes_df[['cram']]\n",
    "\n",
    "## name the column to be a bit more descriptive\n",
    "thousand_genomes_df.rename(columns = {'cram':'1000g_cram'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hifi</th>\n",
       "      <th>sample</th>\n",
       "      <th>1000g_cram</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gs://fc-4310e737-a388-4a10-8c9e-babe06aaf0cf/s...</td>\n",
       "      <td>HG00140</td>\n",
       "      <td>gs://fc-56ac46ea-efc4-4683-b6d5-6d95bed41c5e/C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gs://fc-4310e737-a388-4a10-8c9e-babe06aaf0cf/s...</td>\n",
       "      <td>HG00140</td>\n",
       "      <td>gs://fc-56ac46ea-efc4-4683-b6d5-6d95bed41c5e/C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gs://fc-4310e737-a388-4a10-8c9e-babe06aaf0cf/s...</td>\n",
       "      <td>HG00140</td>\n",
       "      <td>gs://fc-56ac46ea-efc4-4683-b6d5-6d95bed41c5e/C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gs://fc-4310e737-a388-4a10-8c9e-babe06aaf0cf/s...</td>\n",
       "      <td>HG00140</td>\n",
       "      <td>gs://fc-56ac46ea-efc4-4683-b6d5-6d95bed41c5e/C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gs://fc-4310e737-a388-4a10-8c9e-babe06aaf0cf/s...</td>\n",
       "      <td>HG00323</td>\n",
       "      <td>gs://fc-56ac46ea-efc4-4683-b6d5-6d95bed41c5e/C...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                hifi   sample  \\\n",
       "0  gs://fc-4310e737-a388-4a10-8c9e-babe06aaf0cf/s...  HG00140   \n",
       "1  gs://fc-4310e737-a388-4a10-8c9e-babe06aaf0cf/s...  HG00140   \n",
       "2  gs://fc-4310e737-a388-4a10-8c9e-babe06aaf0cf/s...  HG00140   \n",
       "3  gs://fc-4310e737-a388-4a10-8c9e-babe06aaf0cf/s...  HG00140   \n",
       "4  gs://fc-4310e737-a388-4a10-8c9e-babe06aaf0cf/s...  HG00323   \n",
       "\n",
       "                                          1000g_cram  \n",
       "0  gs://fc-56ac46ea-efc4-4683-b6d5-6d95bed41c5e/C...  \n",
       "1  gs://fc-56ac46ea-efc4-4683-b6d5-6d95bed41c5e/C...  \n",
       "2  gs://fc-56ac46ea-efc4-4683-b6d5-6d95bed41c5e/C...  \n",
       "3  gs://fc-56ac46ea-efc4-4683-b6d5-6d95bed41c5e/C...  \n",
       "4  gs://fc-56ac46ea-efc4-4683-b6d5-6d95bed41c5e/C...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## merge the two dataframes\n",
    "ntsm_df1 = pd.merge(\n",
    "    file_df,\n",
    "    thousand_genomes_df,\n",
    "    left_on='sample',\n",
    "    right_index=True)\n",
    "ntsm_df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MGISTL_PAN027_HG06807'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(file_df['sample']) - set(thousand_genomes_df.index.tolist())\n",
    "#file_df['sample']\n",
    "#ntsm_df.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>read_1_fastq</th>\n",
       "      <th>read_2_fastq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>participant_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>HG00096</th>\n",
       "      <td>gs://fc-47de7dae-e8e6-429c-b760-b4ba49136eee/1...</td>\n",
       "      <td>gs://fc-47de7dae-e8e6-429c-b760-b4ba49136eee/1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HG00097</th>\n",
       "      <td>gs://fc-47de7dae-e8e6-429c-b760-b4ba49136eee/1...</td>\n",
       "      <td>gs://fc-47de7dae-e8e6-429c-b760-b4ba49136eee/1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HG00099</th>\n",
       "      <td>gs://fc-47de7dae-e8e6-429c-b760-b4ba49136eee/1...</td>\n",
       "      <td>gs://fc-47de7dae-e8e6-429c-b760-b4ba49136eee/1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HG00100</th>\n",
       "      <td>gs://fc-47de7dae-e8e6-429c-b760-b4ba49136eee/1...</td>\n",
       "      <td>gs://fc-47de7dae-e8e6-429c-b760-b4ba49136eee/1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HG00101</th>\n",
       "      <td>gs://fc-47de7dae-e8e6-429c-b760-b4ba49136eee/1...</td>\n",
       "      <td>gs://fc-47de7dae-e8e6-429c-b760-b4ba49136eee/1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     read_1_fastq  \\\n",
       "participant_id                                                      \n",
       "HG00096         gs://fc-47de7dae-e8e6-429c-b760-b4ba49136eee/1...   \n",
       "HG00097         gs://fc-47de7dae-e8e6-429c-b760-b4ba49136eee/1...   \n",
       "HG00099         gs://fc-47de7dae-e8e6-429c-b760-b4ba49136eee/1...   \n",
       "HG00100         gs://fc-47de7dae-e8e6-429c-b760-b4ba49136eee/1...   \n",
       "HG00101         gs://fc-47de7dae-e8e6-429c-b760-b4ba49136eee/1...   \n",
       "\n",
       "                                                     read_2_fastq  \n",
       "participant_id                                                     \n",
       "HG00096         gs://fc-47de7dae-e8e6-429c-b760-b4ba49136eee/1...  \n",
       "HG00097         gs://fc-47de7dae-e8e6-429c-b760-b4ba49136eee/1...  \n",
       "HG00099         gs://fc-47de7dae-e8e6-429c-b760-b4ba49136eee/1...  \n",
       "HG00100         gs://fc-47de7dae-e8e6-429c-b760-b4ba49136eee/1...  \n",
       "HG00101         gs://fc-47de7dae-e8e6-429c-b760-b4ba49136eee/1...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Read in 1000G data from another workspace\n",
    "## instead of cram files (as before) we'll use fastq files directly so we're not dependent\n",
    "## on the public hg18.fa file, which has been giving problems.\n",
    "## We will be using this to compare against out submission to make sure that\n",
    "## the data comes from the same samples\n",
    "t2t_reads_df = table_to_dataframe(\"participant\", \n",
    "                                 workspace_namespace=\"anvil-datastorage\", \n",
    "                                 workspace=\"AnVIL_T2T\")\n",
    "t2t_reads_df = t2t_reads_df[['read_1_fastq', 'read_2_fastq']]\n",
    "\n",
    "t2t_reads_df.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# there is one sample that's not present in the 1000_genomes. For this we add these two fastq files\n",
    "# (the ntsm workflow can take these instead of .cram or .bam)\n",
    "fq1='gs://fc-4310e737-a388-4a10-8c9e-babe06aaf0cf/submissions/656ace19-660a-44d6-b58a-09a322957a78--WUSTL_CELL_HIFI/MGISTL-PAN027/illumina/HTTMGDSX2_CCTGCAAGAC-GCATCATAGC_L002_R1.fastq.gz'\n",
    "fq2='gs://fc-4310e737-a388-4a10-8c9e-babe06aaf0cf/submissions/656ace19-660a-44d6-b58a-09a322957a78--WUSTL_CELL_HIFI/MGISTL-PAN027/illumina/HTTMGDSX2_CCTGCAAGAC-GCATCATAGC_L002_R2.fastq.gz'\n",
    "\n",
    "t2t_reads_df.loc['MGISTL_PAN027_HG06807']  = [fq1,fq2]\n",
    "t2t_reads_df.loc[['MGISTL_PAN027_HG06807']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## merge the two dataframes\n",
    "ntsm_df = pd.merge(\n",
    "    ntsm_df1,\n",
    "    t2t_reads_df,\n",
    "    left_on='sample',\n",
    "    right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hifi</th>\n",
       "      <th>sample</th>\n",
       "      <th>1000g_cram</th>\n",
       "      <th>read_1_fastq</th>\n",
       "      <th>read_2_fastq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gs://fc-4310e737-a388-4a10-8c9e-babe06aaf0cf/s...</td>\n",
       "      <td>HG00140</td>\n",
       "      <td>gs://fc-56ac46ea-efc4-4683-b6d5-6d95bed41c5e/C...</td>\n",
       "      <td>gs://fc-47de7dae-e8e6-429c-b760-b4ba49136eee/1...</td>\n",
       "      <td>gs://fc-47de7dae-e8e6-429c-b760-b4ba49136eee/1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gs://fc-4310e737-a388-4a10-8c9e-babe06aaf0cf/s...</td>\n",
       "      <td>HG00140</td>\n",
       "      <td>gs://fc-56ac46ea-efc4-4683-b6d5-6d95bed41c5e/C...</td>\n",
       "      <td>gs://fc-47de7dae-e8e6-429c-b760-b4ba49136eee/1...</td>\n",
       "      <td>gs://fc-47de7dae-e8e6-429c-b760-b4ba49136eee/1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gs://fc-4310e737-a388-4a10-8c9e-babe06aaf0cf/s...</td>\n",
       "      <td>HG00140</td>\n",
       "      <td>gs://fc-56ac46ea-efc4-4683-b6d5-6d95bed41c5e/C...</td>\n",
       "      <td>gs://fc-47de7dae-e8e6-429c-b760-b4ba49136eee/1...</td>\n",
       "      <td>gs://fc-47de7dae-e8e6-429c-b760-b4ba49136eee/1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gs://fc-4310e737-a388-4a10-8c9e-babe06aaf0cf/s...</td>\n",
       "      <td>HG00140</td>\n",
       "      <td>gs://fc-56ac46ea-efc4-4683-b6d5-6d95bed41c5e/C...</td>\n",
       "      <td>gs://fc-47de7dae-e8e6-429c-b760-b4ba49136eee/1...</td>\n",
       "      <td>gs://fc-47de7dae-e8e6-429c-b760-b4ba49136eee/1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gs://fc-4310e737-a388-4a10-8c9e-babe06aaf0cf/s...</td>\n",
       "      <td>HG00323</td>\n",
       "      <td>gs://fc-56ac46ea-efc4-4683-b6d5-6d95bed41c5e/C...</td>\n",
       "      <td>gs://fc-47de7dae-e8e6-429c-b760-b4ba49136eee/1...</td>\n",
       "      <td>gs://fc-47de7dae-e8e6-429c-b760-b4ba49136eee/1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                hifi   sample  \\\n",
       "0  gs://fc-4310e737-a388-4a10-8c9e-babe06aaf0cf/s...  HG00140   \n",
       "1  gs://fc-4310e737-a388-4a10-8c9e-babe06aaf0cf/s...  HG00140   \n",
       "2  gs://fc-4310e737-a388-4a10-8c9e-babe06aaf0cf/s...  HG00140   \n",
       "3  gs://fc-4310e737-a388-4a10-8c9e-babe06aaf0cf/s...  HG00140   \n",
       "4  gs://fc-4310e737-a388-4a10-8c9e-babe06aaf0cf/s...  HG00323   \n",
       "\n",
       "                                          1000g_cram  \\\n",
       "0  gs://fc-56ac46ea-efc4-4683-b6d5-6d95bed41c5e/C...   \n",
       "1  gs://fc-56ac46ea-efc4-4683-b6d5-6d95bed41c5e/C...   \n",
       "2  gs://fc-56ac46ea-efc4-4683-b6d5-6d95bed41c5e/C...   \n",
       "3  gs://fc-56ac46ea-efc4-4683-b6d5-6d95bed41c5e/C...   \n",
       "4  gs://fc-56ac46ea-efc4-4683-b6d5-6d95bed41c5e/C...   \n",
       "\n",
       "                                        read_1_fastq  \\\n",
       "0  gs://fc-47de7dae-e8e6-429c-b760-b4ba49136eee/1...   \n",
       "1  gs://fc-47de7dae-e8e6-429c-b760-b4ba49136eee/1...   \n",
       "2  gs://fc-47de7dae-e8e6-429c-b760-b4ba49136eee/1...   \n",
       "3  gs://fc-47de7dae-e8e6-429c-b760-b4ba49136eee/1...   \n",
       "4  gs://fc-47de7dae-e8e6-429c-b760-b4ba49136eee/1...   \n",
       "\n",
       "                                        read_2_fastq  \n",
       "0  gs://fc-47de7dae-e8e6-429c-b760-b4ba49136eee/1...  \n",
       "1  gs://fc-47de7dae-e8e6-429c-b760-b4ba49136eee/1...  \n",
       "2  gs://fc-47de7dae-e8e6-429c-b760-b4ba49136eee/1...  \n",
       "3  gs://fc-47de7dae-e8e6-429c-b760-b4ba49136eee/1...  \n",
       "4  gs://fc-47de7dae-e8e6-429c-b760-b4ba49136eee/1...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(ntsm_df.shape)\n",
    "ntsm_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload To Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create tables for running NTSM and ReadStats\n",
    "dataframe_to_table(\"ntsm_tmp\",      ntsm_df, WORKSPACE, PROJECT)\n",
    "#dataframe_to_table(\"readstats\", file_df, WORKSPACE, PROJECT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
